{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.mllib.clustering import LDA\n",
    "from pyspark.mllib.linalg import Vectors as MLlibVectors\n",
    "from pyspark.mllib.random import RandomRDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mobod2021/mob2021031/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_txt(data_path, min_token_tf, max_token_tf, min_token_length, min_doc_length=50, is_vw_format=False):\n",
    "    time_start = time.time()\n",
    "    sqlContext = SQLContext(sc)\n",
    "\n",
    "    def parse_file(kv):\n",
    "        line = kv if is_vw_format else kv[1]\n",
    "        line = line.replace('\\n', ' ').replace('\\t', ' ')\n",
    "        \n",
    "        if is_vw_format:\n",
    "            line_list = []\n",
    "            for token in line.split(' ')[1: ]:\n",
    "                lst = token.split(':')\n",
    "                if len(lst) == 1:\n",
    "                    line_list.append(token)\n",
    "                else:\n",
    "                    line_list += [lst[0]] * int(float(lst[1]))\n",
    "            line = ' '.join(line_list)\n",
    "        \n",
    "        for p in string.punctuation:\n",
    "            line = line.replace(p, ' ')\n",
    "        \n",
    "        tokens = [e.strip().lower() for e in line.strip().split(' ') if len(e) > 0]\n",
    "        if is_vw_format:\n",
    "            return tokens\n",
    "        else:\n",
    "            return (kv[0], tokens)\n",
    "\n",
    "\n",
    "    def filter_token(kv):\n",
    "        token = kv[0]\n",
    "        value = kv[1]\n",
    "\n",
    "        if value > max_token_tf or value < min_token_tf:\n",
    "            return False\n",
    "\n",
    "        if len(token) < min_token_length:\n",
    "            return False\n",
    "\n",
    "        if token in stopwords_:\n",
    "            return False\n",
    "\n",
    "        for i in '0123456789':\n",
    "            if i in token:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    def get_tokens(tokens):\n",
    "        if is_vw_format:\n",
    "            return tokens\n",
    "        return tokens[1]\n",
    "\n",
    "\n",
    "    def parseVectors(line):\n",
    "        return [int(line[2]), line[0]]\n",
    "\n",
    "\n",
    "    if is_vw_format:\n",
    "        dataset = sc.textFile(data_path)\n",
    "    else:\n",
    "        dataset = sc.wholeTextFiles(\"{}/*\".format(data_path))\n",
    "    dataset = dataset.map(parse_file)\n",
    "    \n",
    "    word_counts = (dataset\n",
    "                   .flatMap(lambda path_with_tokens: ((token, 1) for token in get_tokens(path_with_tokens)))\n",
    "                   .reduceByKey(lambda cnt_1, cnt_2: cnt_1 + cnt_2)\n",
    "                   .sortBy(lambda token_with_cnt: -token_with_cnt[1]))\n",
    "\n",
    "    stopwords_ = set(stopwords.words('english'))\n",
    "\n",
    "    word_counts = word_counts.filter(filter_token)\n",
    "    vocab = set([e[0] for e in word_counts.collect()])\n",
    "\n",
    "    print('Total number of tokens: {0}'.format(len(vocab)))\n",
    "    \n",
    "    i = 0\n",
    "    if is_vw_format:\n",
    "        dataset = (dataset\n",
    "                   .map(lambda kv: (i, list(filter(lambda t: t in vocab, kv))))\n",
    "                   .filter(lambda kv: len(kv[1]) > min_doc_length))\n",
    "    else:\n",
    "        dataset = (dataset\n",
    "                   .map(lambda kv: (kv[0].split('/')[-1], list(filter(lambda t: t in vocab, kv[1]))))\n",
    "                   .filter(lambda kv: len(kv[1]) > min_doc_length))\n",
    "    \n",
    "    print('Total number of documents: {}'.format(dataset.count()))\n",
    "    \n",
    "    data_df = sqlContext.createDataFrame(dataset, ['id', 'tokens'])\n",
    "    \n",
    "    data_df = data_df.drop(\"id\")\n",
    "    \n",
    "    data_df = data_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "    \n",
    "#     data_df.show()\n",
    "    \n",
    "    cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"vectors\")\n",
    "    cv_model = cv.fit(data_df)\n",
    "    df_vect = cv_model.transform(data_df)\n",
    "\n",
    "    bow = (df_vect\n",
    "           .select('vectors', 'tokens', 'id')\n",
    "           .rdd.map(parseVectors)\n",
    "           .mapValues(MLlibVectors.fromML)\n",
    "           .map(list))\n",
    "    \n",
    "    nnz = sum(bow.map(lambda x: list(x[1].values)).reduce(lambda x, y: x + y))\n",
    "    print('Total collection size: {}'.format(nnz))\n",
    "\n",
    "    print('Elapsed time : {} sec.'.format(int(time.time() - time_start)))\n",
    "    return bow, cv_model, nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TopicModel:\n",
    "    \n",
    "    def __init__(self, num_topics, cv_model, nnz, num_document_passes, use_phi_broadcast=True, beta=0.0):\n",
    "        self.num_topics=num_topics      # число тем в модели\n",
    "        self.cv_model_vocabulary=cv_model.vocabulary          # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "        self.nnz=nnz                    # общее число словопозиций в коллекции\n",
    "        self.num_document_passes=num_document_passes     # число проходов по документу на E-шаге\n",
    "        self.use_phi_broadcast=use_phi_broadcast     # использование бродкастинга матрицы $\\Phi$\n",
    "        self.beta=beta\n",
    "        self.perplexity_list=[]\n",
    "        \n",
    "        phiwt_np = np.random.random((len(self.cv_model_vocabulary), self.num_topics))\n",
    "        \n",
    "        if self.use_phi_broadcast:\n",
    "            self.phiwt = sc.broadcast(phiwt_np)\n",
    "        else:\n",
    "            self.phiwt = phiwt_np\n",
    "                \n",
    "    def fit(self, bow_data, num_collection_passes=10):\n",
    "\n",
    "        self.perplexity_list = []\n",
    "        time_start = time.time()\n",
    "        for _ in range(num_collection_passes):\n",
    "            \n",
    "            def process_document(documents, \n",
    "                                 num_topics=self.num_topics, \n",
    "                                 num_document_passes=self.num_document_passes,\n",
    "                                 phiwt=self.phiwt, \n",
    "                                 use_phi_broadcast=self.use_phi_broadcast):\n",
    "                \n",
    "                theta = np.array([1/num_topics] * num_topics)\n",
    "                n_dw = np.zeros(documents.size)\n",
    "                n_dw[documents.indices] = documents.values\n",
    "                \n",
    "                phi = phiwt.value if use_phi_broadcast else phiwt\n",
    "                \n",
    "                for _ in range(num_document_passes):\n",
    "                    _ptdw = np.einsum(\"wt,t->tw\", phi, theta)\n",
    "                    ptdw = _ptdw / np.sum(_ptdw, axis=0, keepdims=True)\n",
    "                    \n",
    "                    _theta = np.einsum(\"t,wt->w\", n_dw, ptdw)\n",
    "                    theta = _theta / np.sum(_theta, axis=0, keepdims=True)\n",
    "                \n",
    "                n_wt = np.einsum(\"w,tw->wt\", n_dw, ptdw)\n",
    "                \n",
    "                return n_wt, (n_dw * np.log((phi * theta).sum(axis=1))).sum()\n",
    "        \n",
    "            def E_part(rows):\n",
    "                for row in rows:\n",
    "                    _, documents = row\n",
    "                    n_wt, perplexity = process_document(documents)\n",
    "                    yield n_wt, perplexity\n",
    "\n",
    "            E = bow_data.partitionBy(5).mapPartitions(E_part)\n",
    "\n",
    "            n_wt, perplexity = E.reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "            phi = self.phiwt.value if self.use_phi_broadcast else self.phiwt\n",
    "            \n",
    "            phiwt_tmp = np.maximum(n_wt + 0.1*phi + self.beta, 0)\n",
    "            phiwt  = phiwt_tmp / phiwt_tmp.sum(axis=0, keepdims=True)\n",
    "\n",
    "            if self.use_phi_broadcast:\n",
    "                self.phiwt = sc.broadcast(phiwt)\n",
    "            else:\n",
    "                self.phiwt = phiwt\n",
    "\n",
    "            self.perplexity_list.append(np.exp(-perplexity/ self.nnz))\n",
    "        \n",
    "        print(\"Done\")\n",
    "        print('Elapsed time : {} sec.'.format(int(time.time() - time_start)))\n",
    "#         with open(\"time.txt\", 'a') as f:\n",
    "#             f.write(\"{} {}\\n\".format(self.num_topics, int(time.time() - time_start)))\n",
    "        \n",
    "    def print_perplexity(self):\n",
    "        print(self.perplexity_list)\n",
    "    \n",
    "    def print_topics(self, num_tokens=10):\n",
    "        indcs = self.PHIwt.argsort(axis=0)[-num_tokens:][::-1]\n",
    "        for idx, i_w in enumerate(range(indcs.shape[1])):\n",
    "            print(\"topic_id: {}\".format(idx))\n",
    "            for i in indcs[:,i_w]:\n",
    "                print(model.cv_model_vocabulary[i])\n",
    "            print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ssc = StreamingContext(sc, 1)\n",
    "# conf = SparkConf()\n",
    "# conf.set(\"spark.executor.memory\", \"10g\")\n",
    "# conf.set(\"spark.driver.memory\", \"8g\")\n",
    "# conf.set(\"spark.core.connection.ack.wait.timeout\", \"1200\")\n",
    "# # conf.set(\"spark.executor.heartbeatInterval\", \"10s\")\n",
    "# conf.set(\"spark.executor.heartbeatInterval\",\"3600s\")\n",
    "\n",
    "# SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "# SparkContext.setSystemProperty('spark.driver.memory', '2g')\n",
    "# sc = SparkContext(\"local\", \"App\")\n",
    "sc = SparkContext.getOrCreate();\n",
    "# sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/data/mobod/tm/vw.wiki-en-20K.txt\" # /data/mobod/tm/vw.wiki-en-20K.txt\n",
    "min_token_tf = 10\n",
    "max_token_tf = 30000\n",
    "min_token_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 42143\n",
      "Total number of documents: 16029\n",
      "Total collection size: 5193241.0\n",
      "Elapsed time : 90 sec.\n"
     ]
    }
   ],
   "source": [
    "bow, cv_model, nnz = read_txt(data_path, min_token_tf, max_token_tf, min_token_length, min_doc_length=50, is_vw_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед проведением экспериментов, проверим, что данные разбиты на достаточное число партиций и что среди них нет вырожденных (существенно меньших по объёму, чем прочие). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_row_in_partitions(rows):\n",
    "    count = 0\n",
    "    for _ in rows:\n",
    "        count += 1\n",
    "    yield count     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 6.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8038, 7991]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bow.mapPartitions(count_row_in_partitions).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 5.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3206, 3206, 3207, 3205, 3205]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bow.partitionBy(5).mapPartitions(count_row_in_partitions).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценить время работы при num_document_passes=5 и num_collection_passes=10, без broadcast переменной,  с числом тем num_topics = 10, 20, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics_list = [10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num topics:  10\n",
      "Done\n",
      "Elapsed time : 4559 sec.\n",
      "Num topics:  20\n",
      "Done\n",
      "Elapsed time : 9360 sec.\n",
      "Num topics:  50\n",
      "Done\n",
      "Elapsed time : 18573 sec.\n"
     ]
    }
   ],
   "source": [
    "for num_topics in num_topics_list:\n",
    "    print('Num topics: ', num_topics)\n",
    "    model = TopicModel(num_topics=num_topics,   # число тем в модели\n",
    "                   cv_model=cv_model,           # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                     # общее число словопозиций в коллекции\n",
    "                   num_document_passes=10,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=False,     # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=0.0)  \n",
    "    model.fit1(bow, num_collection_passes=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Оценить время работы при num_document_passes=5 и num_collection_passes=10, с broadcast переменной,  с числом тем num_topics = 10, 20, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num topics:  10\n",
      "Done\n",
      "Elapsed time : 3970 sec.\n",
      "Num topics:  20\n",
      "Done\n",
      "Elapsed time : 8107 sec.\n",
      "Num topics:  50\n",
      "Done\n",
      "Elapsed time : 18398 sec.\n"
     ]
    }
   ],
   "source": [
    "for num_topics in num_topics_list:\n",
    "    print('Num topics: ', num_topics)\n",
    "    model = TopicModel(num_topics=num_topics,  # число тем в модели\n",
    "                   cv_model=cv_model,          # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                    # общее число словопозиций в коллекции\n",
    "                   num_document_passes=10,     # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=True,     # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=0.0)  \n",
    "    model.fit1(bow, num_collection_passes=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При `num_topics=20` и `num_collection_passes=10` попробовать различные значения `num_document_passes` = 1, 2, 5, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TopicModel(num_topics=20, # число тем в модели\n",
    "                   cv_model=cv_model,           # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                     # общее число словопозиций в коллекции\n",
    "                   num_document_passes=1,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=False,   # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=0.0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Elapsed time : 745 sec.\n",
      "CPU times: user 1.13 s, sys: 316 ms, total: 1.44 s\n",
      "Wall time: 12min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(bow, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_id: 0\n",
      "town\n",
      "party\n",
      "game\n",
      "union\n",
      "king\n",
      "cup\n",
      "station\n",
      "club\n",
      "art\n",
      "band\n",
      "--------\n",
      "topic_id: 1\n",
      "river\n",
      "district\n",
      "system\n",
      "church\n",
      "film\n",
      "game\n",
      "album\n",
      "road\n",
      "army\n",
      "version\n",
      "--------\n",
      "topic_id: 2\n",
      "film\n",
      "song\n",
      "london\n",
      "party\n",
      "album\n",
      "king\n",
      "road\n",
      "building\n",
      "support\n",
      "community\n",
      "--------\n",
      "topic_id: 3\n",
      "park\n",
      "army\n",
      "album\n",
      "man\n",
      "political\n",
      "award\n",
      "black\n",
      "book\n",
      "research\n",
      "street\n",
      "--------\n",
      "topic_id: 4\n",
      "film\n",
      "club\n",
      "album\n",
      "record\n",
      "king\n",
      "radio\n",
      "station\n",
      "works\n",
      "next\n",
      "party\n",
      "--------\n",
      "topic_id: 5\n",
      "film\n",
      "party\n",
      "river\n",
      "song\n",
      "church\n",
      "game\n",
      "station\n",
      "art\n",
      "building\n",
      "education\n",
      "--------\n",
      "topic_id: 6\n",
      "party\n",
      "song\n",
      "church\n",
      "town\n",
      "building\n",
      "station\n",
      "road\n",
      "right\n",
      "river\n",
      "full\n",
      "--------\n",
      "topic_id: 7\n",
      "game\n",
      "club\n",
      "development\n",
      "league\n",
      "park\n",
      "william\n",
      "book\n",
      "system\n",
      "cup\n",
      "next\n",
      "--------\n",
      "topic_id: 8\n",
      "game\n",
      "film\n",
      "league\n",
      "party\n",
      "road\n",
      "river\n",
      "album\n",
      "band\n",
      "king\n",
      "club\n",
      "--------\n",
      "topic_id: 9\n",
      "king\n",
      "system\n",
      "center\n",
      "album\n",
      "army\n",
      "league\n",
      "club\n",
      "england\n",
      "women\n",
      "games\n",
      "--------\n",
      "topic_id: 10\n",
      "film\n",
      "game\n",
      "league\n",
      "father\n",
      "station\n",
      "album\n",
      "children\n",
      "party\n",
      "night\n",
      "show\n",
      "--------\n",
      "topic_id: 11\n",
      "film\n",
      "church\n",
      "party\n",
      "club\n",
      "album\n",
      "london\n",
      "king\n",
      "england\n",
      "women\n",
      "power\n",
      "--------\n",
      "topic_id: 12\n",
      "album\n",
      "club\n",
      "party\n",
      "town\n",
      "road\n",
      "radio\n",
      "art\n",
      "law\n",
      "research\n",
      "form\n",
      "--------\n",
      "topic_id: 13\n",
      "club\n",
      "game\n",
      "party\n",
      "song\n",
      "album\n",
      "league\n",
      "park\n",
      "london\n",
      "community\n",
      "version\n",
      "--------\n",
      "topic_id: 14\n",
      "league\n",
      "film\n",
      "town\n",
      "art\n",
      "song\n",
      "road\n",
      "game\n",
      "son\n",
      "center\n",
      "park\n",
      "--------\n",
      "topic_id: 15\n",
      "film\n",
      "league\n",
      "album\n",
      "town\n",
      "river\n",
      "church\n",
      "support\n",
      "station\n",
      "law\n",
      "german\n",
      "--------\n",
      "topic_id: 16\n",
      "town\n",
      "league\n",
      "song\n",
      "system\n",
      "station\n",
      "band\n",
      "film\n",
      "man\n",
      "church\n",
      "said\n",
      "--------\n",
      "topic_id: 17\n",
      "film\n",
      "road\n",
      "son\n",
      "support\n",
      "cup\n",
      "system\n",
      "community\n",
      "london\n",
      "king\n",
      "building\n",
      "--------\n",
      "topic_id: 18\n",
      "league\n",
      "film\n",
      "party\n",
      "town\n",
      "london\n",
      "park\n",
      "station\n",
      "man\n",
      "president\n",
      "game\n",
      "--------\n",
      "topic_id: 19\n",
      "film\n",
      "church\n",
      "album\n",
      "man\n",
      "record\n",
      "art\n",
      "park\n",
      "party\n",
      "community\n",
      "works\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "model.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0031400293603694, 11590.876243136421, 11589.343341274445, 11589.343320963952, 11589.343320691012, 11589.343320685926, 11589.343320685866, 11589.343320685866, 11589.343320685866, 11589.343320685988]\n"
     ]
    }
   ],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TopicModel(num_topics=20, # число тем в модели\n",
    "                   cv_model=cv_model,           # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                     # общее число словопозиций в коллекции\n",
    "                   num_document_passes=2,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=False,   # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=0.0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Elapsed time : 1059 sec.\n",
      "CPU times: user 1.07 s, sys: 308 ms, total: 1.38 s\n",
      "Wall time: 17min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(bow, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_id: 0\n",
      "film\n",
      "production\n",
      "center\n",
      "church\n",
      "research\n",
      "system\n",
      "cause\n",
      "museum\n",
      "education\n",
      "file\n",
      "--------\n",
      "topic_id: 1\n",
      "party\n",
      "castle\n",
      "chateau\n",
      "parties\n",
      "region\n",
      "river\n",
      "building\n",
      "england\n",
      "league\n",
      "democratic\n",
      "--------\n",
      "topic_id: 2\n",
      "league\n",
      "cup\n",
      "album\n",
      "club\n",
      "football\n",
      "guitar\n",
      "vocals\n",
      "track\n",
      "games\n",
      "video\n",
      "--------\n",
      "topic_id: 3\n",
      "station\n",
      "research\n",
      "london\n",
      "book\n",
      "railway\n",
      "students\n",
      "royal\n",
      "center\n",
      "council\n",
      "established\n",
      "--------\n",
      "topic_id: 4\n",
      "king\n",
      "emperor\n",
      "china\n",
      "province\n",
      "empire\n",
      "roman\n",
      "site\n",
      "dehydrogenase\n",
      "period\n",
      "william\n",
      "--------\n",
      "topic_id: 5\n",
      "game\n",
      "station\n",
      "version\n",
      "london\n",
      "right\n",
      "published\n",
      "air\n",
      "film\n",
      "church\n",
      "control\n",
      "--------\n",
      "topic_id: 6\n",
      "game\n",
      "air\n",
      "book\n",
      "station\n",
      "engine\n",
      "using\n",
      "island\n",
      "even\n",
      "character\n",
      "film\n",
      "--------\n",
      "topic_id: 7\n",
      "regiment\n",
      "foot\n",
      "raised\n",
      "film\n",
      "bus\n",
      "park\n",
      "battalion\n",
      "river\n",
      "division\n",
      "championship\n",
      "--------\n",
      "topic_id: 8\n",
      "model\n",
      "species\n",
      "town\n",
      "water\n",
      "support\n",
      "power\n",
      "system\n",
      "given\n",
      "similar\n",
      "units\n",
      "--------\n",
      "topic_id: 9\n",
      "song\n",
      "chart\n",
      "championship\n",
      "episode\n",
      "club\n",
      "film\n",
      "version\n",
      "singles\n",
      "play\n",
      "points\n",
      "--------\n",
      "topic_id: 10\n",
      "league\n",
      "club\n",
      "album\n",
      "player\n",
      "band\n",
      "goals\n",
      "game\n",
      "film\n",
      "football\n",
      "show\n",
      "--------\n",
      "topic_id: 11\n",
      "linear\n",
      "socorro\n",
      "peak\n",
      "kitt\n",
      "spacewatch\n",
      "anderson\n",
      "mount\n",
      "station\n",
      "river\n",
      "neat\n",
      "--------\n",
      "topic_id: 12\n",
      "saint\n",
      "king\n",
      "roman\n",
      "sur\n",
      "les\n",
      "des\n",
      "air\n",
      "song\n",
      "church\n",
      "total\n",
      "--------\n",
      "topic_id: 13\n",
      "district\n",
      "town\n",
      "french\n",
      "church\n",
      "party\n",
      "president\n",
      "children\n",
      "street\n",
      "election\n",
      "court\n",
      "--------\n",
      "topic_id: 14\n",
      "church\n",
      "art\n",
      "show\n",
      "children\n",
      "german\n",
      "district\n",
      "site\n",
      "hall\n",
      "building\n",
      "written\n",
      "--------\n",
      "topic_id: 15\n",
      "film\n",
      "game\n",
      "album\n",
      "love\n",
      "award\n",
      "club\n",
      "band\n",
      "isbn\n",
      "system\n",
      "take\n",
      "--------\n",
      "topic_id: 16\n",
      "matter\n",
      "park\n",
      "system\n",
      "file\n",
      "game\n",
      "town\n",
      "party\n",
      "william\n",
      "washington\n",
      "election\n",
      "--------\n",
      "topic_id: 17\n",
      "film\n",
      "miss\n",
      "park\n",
      "album\n",
      "poland\n",
      "president\n",
      "aircraft\n",
      "song\n",
      "party\n",
      "road\n",
      "--------\n",
      "topic_id: 18\n",
      "trust\n",
      "bgcolor\n",
      "community\n",
      "nhs\n",
      "road\n",
      "hospital\n",
      "white\n",
      "programs\n",
      "foundation\n",
      "ret\n",
      "--------\n",
      "topic_id: 19\n",
      "party\n",
      "congress\n",
      "indian\n",
      "india\n",
      "army\n",
      "london\n",
      "william\n",
      "river\n",
      "son\n",
      "battle\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "model.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.002166420435021, 11525.038954980118, 11488.647874276287, 11432.740235584848, 11354.367263654498, 11254.982155642618, 11133.267272163981, 10982.580921302015, 10788.087364622208, 10529.36571757355]\n"
     ]
    }
   ],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TopicModel(num_topics=20, # число тем в модели\n",
    "                   cv_model=cv_model,           # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                     # общее число словопозиций в коллекции\n",
    "                   num_document_passes=5,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=False,   # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=0.0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Elapsed time : 2143 sec.\n",
      "CPU times: user 1.18 s, sys: 352 ms, total: 1.53 s\n",
      "Wall time: 35min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(bow, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_id: 0\n",
      "royal\n",
      "army\n",
      "regiment\n",
      "foot\n",
      "infantry\n",
      "battalion\n",
      "bgcolor\n",
      "men\n",
      "ship\n",
      "corps\n",
      "--------\n",
      "topic_id: 1\n",
      "album\n",
      "song\n",
      "band\n",
      "records\n",
      "songs\n",
      "chart\n",
      "king\n",
      "guitar\n",
      "love\n",
      "track\n",
      "--------\n",
      "topic_id: 2\n",
      "show\n",
      "film\n",
      "star\n",
      "big\n",
      "radio\n",
      "award\n",
      "red\n",
      "man\n",
      "little\n",
      "video\n",
      "--------\n",
      "topic_id: 3\n",
      "championship\n",
      "race\n",
      "points\n",
      "round\n",
      "racing\n",
      "win\n",
      "men\n",
      "event\n",
      "tournament\n",
      "champion\n",
      "--------\n",
      "topic_id: 4\n",
      "law\n",
      "president\n",
      "political\n",
      "court\n",
      "king\n",
      "act\n",
      "french\n",
      "social\n",
      "minister\n",
      "rights\n",
      "--------\n",
      "topic_id: 5\n",
      "league\n",
      "club\n",
      "game\n",
      "cup\n",
      "students\n",
      "games\n",
      "education\n",
      "player\n",
      "goals\n",
      "football\n",
      "--------\n",
      "topic_id: 6\n",
      "church\n",
      "linear\n",
      "socorro\n",
      "william\n",
      "isbn\n",
      "peak\n",
      "james\n",
      "opera\n",
      "kitt\n",
      "spacewatch\n",
      "--------\n",
      "topic_id: 7\n",
      "saint\n",
      "aircraft\n",
      "air\n",
      "german\n",
      "africa\n",
      "population\n",
      "france\n",
      "squadron\n",
      "language\n",
      "airport\n",
      "--------\n",
      "topic_id: 8\n",
      "film\n",
      "father\n",
      "award\n",
      "daughter\n",
      "mother\n",
      "married\n",
      "sir\n",
      "role\n",
      "children\n",
      "london\n",
      "--------\n",
      "topic_id: 9\n",
      "league\n",
      "division\n",
      "football\n",
      "town\n",
      "club\n",
      "stadium\n",
      "game\n",
      "district\n",
      "baseball\n",
      "england\n",
      "--------\n",
      "topic_id: 10\n",
      "chinese\n",
      "system\n",
      "china\n",
      "support\n",
      "version\n",
      "web\n",
      "memory\n",
      "mobile\n",
      "food\n",
      "windows\n",
      "--------\n",
      "topic_id: 11\n",
      "river\n",
      "water\n",
      "trust\n",
      "health\n",
      "areas\n",
      "species\n",
      "lake\n",
      "mountain\n",
      "region\n",
      "sea\n",
      "--------\n",
      "topic_id: 12\n",
      "station\n",
      "party\n",
      "road\n",
      "railway\n",
      "district\n",
      "route\n",
      "street\n",
      "election\n",
      "highway\n",
      "bridge\n",
      "--------\n",
      "topic_id: 13\n",
      "film\n",
      "episode\n",
      "television\n",
      "director\n",
      "character\n",
      "game\n",
      "production\n",
      "show\n",
      "films\n",
      "characters\n",
      "--------\n",
      "topic_id: 14\n",
      "power\n",
      "engine\n",
      "car\n",
      "production\n",
      "prince\n",
      "model\n",
      "energy\n",
      "vehicle\n",
      "speed\n",
      "electric\n",
      "--------\n",
      "topic_id: 15\n",
      "system\n",
      "using\n",
      "example\n",
      "theory\n",
      "form\n",
      "research\n",
      "space\n",
      "information\n",
      "data\n",
      "different\n",
      "--------\n",
      "topic_id: 16\n",
      "force\n",
      "battle\n",
      "forces\n",
      "military\n",
      "navy\n",
      "army\n",
      "air\n",
      "attack\n",
      "training\n",
      "command\n",
      "--------\n",
      "topic_id: 17\n",
      "book\n",
      "published\n",
      "art\n",
      "magazine\n",
      "works\n",
      "show\n",
      "story\n",
      "arts\n",
      "written\n",
      "festival\n",
      "--------\n",
      "topic_id: 18\n",
      "india\n",
      "indian\n",
      "museum\n",
      "island\n",
      "canada\n",
      "party\n",
      "village\n",
      "population\n",
      "temple\n",
      "liberal\n",
      "--------\n",
      "topic_id: 19\n",
      "park\n",
      "site\n",
      "castle\n",
      "building\n",
      "street\n",
      "design\n",
      "hall\n",
      "buildings\n",
      "chateau\n",
      "hill\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "model.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9810176955803374, 11259.338319260123, 10871.226215878696, 10136.359941594508, 8984.999570865597, 7742.519186072006, 6843.55439305915, 6304.399992353714, 5975.885641456235, 5755.43352870641]\n"
     ]
    }
   ],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TopicModel(num_topics=20, # число тем в модели\n",
    "                   cv_model=cv_model,           # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                     # общее число словопозиций в коллекции\n",
    "                   num_document_passes=10,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=False,   # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=0.0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Elapsed time : 3019 sec.\n",
      "CPU times: user 1.31 s, sys: 320 ms, total: 1.63 s\n",
      "Wall time: 50min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(bow, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_id: 0\n",
      "million\n",
      "development\n",
      "economic\n",
      "oil\n",
      "business\n",
      "power\n",
      "companies\n",
      "production\n",
      "services\n",
      "health\n",
      "--------\n",
      "topic_id: 1\n",
      "law\n",
      "president\n",
      "party\n",
      "court\n",
      "election\n",
      "saint\n",
      "canada\n",
      "elected\n",
      "canadian\n",
      "council\n",
      "--------\n",
      "topic_id: 2\n",
      "league\n",
      "championship\n",
      "football\n",
      "game\n",
      "stadium\n",
      "games\n",
      "cup\n",
      "win\n",
      "coach\n",
      "player\n",
      "--------\n",
      "topic_id: 3\n",
      "party\n",
      "church\n",
      "political\n",
      "social\n",
      "movement\n",
      "christian\n",
      "god\n",
      "book\n",
      "women\n",
      "religious\n",
      "--------\n",
      "topic_id: 4\n",
      "station\n",
      "japan\n",
      "japanese\n",
      "opera\n",
      "railway\n",
      "episode\n",
      "stations\n",
      "tokyo\n",
      "network\n",
      "channel\n",
      "--------\n",
      "topic_id: 5\n",
      "river\n",
      "town\n",
      "building\n",
      "park\n",
      "village\n",
      "jpg\n",
      "church\n",
      "lake\n",
      "site\n",
      "street\n",
      "--------\n",
      "topic_id: 6\n",
      "album\n",
      "band\n",
      "song\n",
      "records\n",
      "songs\n",
      "chart\n",
      "guitar\n",
      "video\n",
      "rock\n",
      "track\n",
      "--------\n",
      "topic_id: 7\n",
      "system\n",
      "using\n",
      "model\n",
      "type\n",
      "design\n",
      "engine\n",
      "systems\n",
      "standard\n",
      "available\n",
      "car\n",
      "--------\n",
      "topic_id: 8\n",
      "league\n",
      "cup\n",
      "club\n",
      "emperor\n",
      "division\n",
      "district\n",
      "goals\n",
      "cricket\n",
      "total\n",
      "england\n",
      "--------\n",
      "topic_id: 9\n",
      "london\n",
      "william\n",
      "book\n",
      "published\n",
      "isbn\n",
      "george\n",
      "art\n",
      "married\n",
      "james\n",
      "son\n",
      "--------\n",
      "topic_id: 10\n",
      "german\n",
      "germany\n",
      "russian\n",
      "republic\n",
      "soviet\n",
      "european\n",
      "russia\n",
      "van\n",
      "french\n",
      "dutch\n",
      "--------\n",
      "topic_id: 11\n",
      "army\n",
      "battle\n",
      "military\n",
      "forces\n",
      "force\n",
      "regiment\n",
      "attack\n",
      "killed\n",
      "command\n",
      "division\n",
      "--------\n",
      "topic_id: 12\n",
      "film\n",
      "episode\n",
      "show\n",
      "television\n",
      "award\n",
      "role\n",
      "films\n",
      "story\n",
      "directed\n",
      "movie\n",
      "--------\n",
      "topic_id: 13\n",
      "texas\n",
      "california\n",
      "florida\n",
      "oklahoma\n",
      "ohio\n",
      "angeles\n",
      "carolina\n",
      "star\n",
      "gordon\n",
      "comics\n",
      "--------\n",
      "topic_id: 14\n",
      "air\n",
      "aircraft\n",
      "washington\n",
      "squadron\n",
      "island\n",
      "fort\n",
      "road\n",
      "park\n",
      "wing\n",
      "mile\n",
      "--------\n",
      "topic_id: 15\n",
      "students\n",
      "research\n",
      "education\n",
      "science\n",
      "institute\n",
      "program\n",
      "center\n",
      "society\n",
      "technology\n",
      "schools\n",
      "--------\n",
      "topic_id: 16\n",
      "road\n",
      "india\n",
      "indian\n",
      "route\n",
      "airport\n",
      "station\n",
      "highway\n",
      "railway\n",
      "hong\n",
      "kong\n",
      "--------\n",
      "topic_id: 17\n",
      "linear\n",
      "game\n",
      "socorro\n",
      "peak\n",
      "kitt\n",
      "spacewatch\n",
      "games\n",
      "character\n",
      "player\n",
      "anderson\n",
      "--------\n",
      "topic_id: 18\n",
      "club\n",
      "radio\n",
      "miss\n",
      "del\n",
      "winner\n",
      "league\n",
      "spanish\n",
      "awards\n",
      "cup\n",
      "san\n",
      "--------\n",
      "topic_id: 19\n",
      "species\n",
      "foot\n",
      "form\n",
      "often\n",
      "common\n",
      "usually\n",
      "tree\n",
      "example\n",
      "light\n",
      "animals\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "model.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9539752532315, 10788.128738534579, 9658.761839116385, 8109.908301100955, 6926.145901190617, 6275.731027385971, 5907.875953679706, 5676.900583304337, 5517.366150706584, 5399.501576395475, 5308.210064133085, 5235.350622086657, 5176.46696157842, 5128.810649762238]\n"
     ]
    }
   ],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейшая регуляризация LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beta_list = [0.0, -0.1, -1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TopicModel(num_topics=20,          # число тем в модели\n",
    "                   cv_model=cv_model,          # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                    # общее число словопозиций в коллекции\n",
    "                   num_document_passes=5,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=True,     # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=0.0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Elapsed time : 1744 sec.\n"
     ]
    }
   ],
   "source": [
    "model.fit(bow, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6374.922999087668, 5971.94906111582, 5703.743190814501, 5520.280327351867, 5390.4614142650835, 5294.094546009813, 5220.546188067603, 5163.953001849265, 5119.300763980135, 5083.667488426292]\n"
     ]
    }
   ],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем разряженность матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252206824545584"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.round(model.phiwt.value, decimals=4)==0.0) / (model.phiwt.value.shape[0] * model.phiwt.value.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta: -0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TopicModel(num_topics=20,          # число тем в модели\n",
    "                   cv_model=cv_model,          # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                    # общее число словопозиций в коллекции\n",
    "                   num_document_passes=5,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=True,     # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=-0.1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Elapsed time : 1754 sec.\n"
     ]
    }
   ],
   "source": [
    "model.fit(bow, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.980021687603568, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.round(model.phiwt.value, decimals=4)==0.0) / (model.phiwt.value.shape[0] * model.phiwt.value.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta: -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = TopicModel(num_topics=20,          # число тем в модели\n",
    "                   cv_model=cv_model,          # векторизатор, объект класса `pyspark.ml.feature.CountVectorizer`\n",
    "                   nnz=nnz,                    # общее число словопозиций в коллекции\n",
    "                   num_document_passes=5,      # число проходов по документу на E-шаге\n",
    "                   use_phi_broadcast=True,     # использование бродкастинга матрицы $\\Phi$\n",
    "                   beta=-1.0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(bow, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.round(model.phiwt.value, decimals=4)==0.0) / (model.phiwt.value.shape[0] * model.phiwt.value.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9513.324257630837, 7771.021776248306, 6498.5023868671715, 5854.101607647668, 5510.384859919405, 5306.701951431949, 5176.884582509909, 5090.030398120509, 5029.170717168109, 4985.404751733243]\n"
     ]
    }
   ],
   "source": [
    "model.print_perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_id: 0\n",
      "father\n",
      "son\n",
      "church\n",
      "mother\n",
      "said\n",
      "--------\n",
      "topic_id: 1\n",
      "game\n",
      "road\n",
      "construction\n",
      "airport\n",
      "building\n",
      "--------\n",
      "topic_id: 2\n",
      "research\n",
      "education\n",
      "india\n",
      "students\n",
      "social\n",
      "--------\n",
      "topic_id: 3\n",
      "russian\n",
      "hong\n",
      "chinese\n",
      "japanese\n",
      "jewish\n",
      "--------\n",
      "topic_id: 4\n",
      "party\n",
      "law\n",
      "political\n",
      "election\n",
      "court\n",
      "--------\n",
      "topic_id: 5\n",
      "spanish\n",
      "miss\n",
      "del\n",
      "men\n",
      "san\n",
      "--------\n",
      "topic_id: 6\n",
      "art\n",
      "book\n",
      "isbn\n",
      "published\n",
      "works\n",
      "--------\n",
      "topic_id: 7\n",
      "california\n",
      "president\n",
      "news\n",
      "http\n",
      "texas\n",
      "--------\n",
      "topic_id: 8\n",
      "station\n",
      "linear\n",
      "socorro\n",
      "railway\n",
      "town\n",
      "--------\n",
      "topic_id: 9\n",
      "system\n",
      "systems\n",
      "data\n",
      "using\n",
      "process\n",
      "--------\n",
      "topic_id: 10\n",
      "film\n",
      "television\n",
      "award\n",
      "films\n",
      "role\n",
      "--------\n",
      "topic_id: 11\n",
      "river\n",
      "king\n",
      "species\n",
      "water\n",
      "lake\n",
      "--------\n",
      "topic_id: 12\n",
      "league\n",
      "club\n",
      "cup\n",
      "football\n",
      "round\n",
      "--------\n",
      "topic_id: 13\n",
      "army\n",
      "battle\n",
      "military\n",
      "canadian\n",
      "canada\n",
      "--------\n",
      "topic_id: 14\n",
      "episode\n",
      "character\n",
      "show\n",
      "story\n",
      "man\n",
      "--------\n",
      "topic_id: 15\n",
      "theory\n",
      "form\n",
      "space\n",
      "example\n",
      "case\n",
      "--------\n",
      "topic_id: 16\n",
      "church\n",
      "park\n",
      "street\n",
      "building\n",
      "road\n",
      "--------\n",
      "topic_id: 17\n",
      "album\n",
      "band\n",
      "song\n",
      "records\n",
      "songs\n",
      "--------\n",
      "topic_id: 18\n",
      "game\n",
      "league\n",
      "championship\n",
      "games\n",
      "baseball\n",
      "--------\n",
      "topic_id: 19\n",
      "air\n",
      "aircraft\n",
      "saint\n",
      "engine\n",
      "navy\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "model.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
